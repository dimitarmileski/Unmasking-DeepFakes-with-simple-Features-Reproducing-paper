{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Коцарев/Трајковиќ/Стиков\n",
    "# МЕТОДОЛОГИЈА НА ИСТРАЖУВАЊЕТО ВО ИКТ:\n",
    "## КОЛОКВИУМ 1 5 декември, 2020\n",
    "##### ИМЕ И ПРЕЗИМЕ: Димитар Милески БРОЈ НА ИНДЕКС: 171166"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. (15 поени)** За ова прашање ќе треба да најдете оригинален истражувачки труд на\n",
    "сајтот: Scholar.google.com   \n",
    "Трудот треба да има секција за методи (најчесто поднаслов Methods или Methodology) и\n",
    "да има јасна хипотеза. Бидејќи голем дел од трудовите се достапни само со плаќање\n",
    "(paywalled), на час ви кажавме како да пристапите до нив бесплатно. Целиот колоквиум е\n",
    "поврзан со истиот труд, така што посветете доволно време во изборот на трудот за да\n",
    "можете полесно да ги одговорите сите прашања и задачи.\n",
    "На час не ви кажавме како да цитирате труд, така што ова ќе треба сами да го дознаете.\n",
    "Цитирајте го избраниот труд користејќи го IEEE стилот на цитирање!      \n",
    "ОДГОВОР:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<cite data-cite=\"durall2019unmasking\">durall2019unmasking</cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### bibliography.bib"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "@article{durall2019unmasking,\n",
    "   title={Unmasking deepfakes with simple features},\n",
    "   author={Durall, Ricard and Keuper, Margret and Pfreundt, Franz-Josef and Keuper, Janis},\n",
    "   journal={arXiv preprint arXiv:1911.00686},\n",
    "   year={2019}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### paper.tex"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\begin{abstract}\n",
    "Reproducing paper about DeepFakes with simple Features\\cite{durall2019unmasking} \n",
    "\\end{abstract}\n",
    "\n",
    "\\bibliographystyle{ieee}\n",
    "\\bibliography{bibliography.bib}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Reference_example.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Reference example](reference.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тука е прикажан начинот за референцирање со помош на .bib датотека и .tex LaTeX датотека.  Во мојот случај јас користев OverLeaf - https://www.overleaf.com .  \n",
    "Исто така има начин за референцирање во Jupyter тетратката која може отпосле да генерира pdf со референците.\n",
    "За вториот начин е потребни се ref.bib, citations.tplx, i Compile Article.ipynb кои се наоѓаат во тековниот директориум."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. (45 поени)** Опишете ја методологијата на трудот од претходното прашање во следните\n",
    "категории:        \n",
    "**а) Дали истражувањето е квалитативно или квантитативно?**   \n",
    "Конкретното истражување е квантитативно. Има податоци кои се обработуваат и на крајот се добиваат соодветни бројчани вредности со кои што можеме нешто да закчичиме. \n",
    "Истражувањето спаѓа во групата на квантитативни експериментални истражувања.   \n",
    "**б) Како се собирани податоците?**    \n",
    "За слики со висока резолуција на лицето, искомбинирани се неколку јавни податочни множества.\n",
    "Овие податочни множества вклучуваат податоци за слики од реални луѓе и слики од лица кои се генерирани со алгоритам од компјутерска визија.\n",
    "Податочно множевство со висока резолуција е Faces-HQ за кое што со 20 примероци се постигнати одлични резултати за точност на класификацијата.\n",
    "Податочно множевство со слики со средна резолуција е CelebA кое што исто така постигнува одлични резултати. \n",
    "И на крај податочмно множество со видео секвенци со ниска резолуција FaceForensics++, за кое што е добиена 90% точност при класификацијата.   \n",
    "[FaceHQ](https://github.com/NVlabs/ffhq-dataset) - Податоците се состојат од 70.000 висококвалитетни PNG слики со резолуција 1024 × 1024 и содржат значителни разлики во однос на возраста, етничката припадност и позадината на сликата.   \n",
    "[CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) - CelebFaces (CelebA) е голема податочно множество за атрибути на лице со повеќе од 200 илјади слики на славни лица, секоја со по 40 анотации за атрибути. Сликите во ова податочно множество опфаќаат големи варијации на поза и позадини. CelebA има големи разлики, големи количини и богати прибелешки, вклучително и\n",
    "10.177 идентични лица, 202.599 број на слики на лице, и 40 бинарни атрибутни анотации по слика.   \n",
    "[FaceForensics++](https://github.com/ondyari/FaceForensics) - Податочното множество содржи над 3000 манипулирани видеа од 28 актери во различни сцени.    \n",
    "**в) Која е хипотезата што трудот ја тестира?**   \n",
    "Дали може да се постигне висока точност на бинарна класификацијата на лажни и вистински лица со малку примероци и едноставни карактеристики за учење."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**г) Кој статистички тест е критериум за прифаќање/одбивање на хипотезата?**       \n",
    "Вистински позитивни (анг.Тrue Positive) - ова се правилно предвидените позитивни вредности што значи дека вредноста на реалната класа, а вредноста на предвидената класа е вистинската.   \n",
    "\n",
    "Вистински негативни (анг.Тrue Negative) - ова се правилно предвидените негативни вредности што значи дека вредноста на реалната класа не е погодена.   \n",
    "\n",
    "Лажни позитивни и лажни негативни, се појавуваат кога  вистинска класа е различна со предвидената класа.   \n",
    "\n",
    "Лажни позитиви (анг.False Positive)     \n",
    "\n",
    "Лажни негативи (анг.False Negative)   \n",
    "Откако ќе ги разберете овие четири параметри, тогаш можеме да ги пресметаме резултатите за Точност, Прецизност, чувствителност (анг.Recall) и F1.   \n",
    "\n",
    "Точност - Точноста е најинтуитивната мерка за перформанси и таа е едноставно сооднос на правилно предвидено набудување со вкупните набудувања.   \n",
    "\n",
    "Accuracy = TP + TN / TP + FP + FN + TN   \n",
    "\n",
    "Прецизност - Прецизност е односот на правилно предвидени позитивни набудувања со вкупните предвидени позитивни набудувања.   \n",
    "\n",
    "Precision = TP / TP + FP   \n",
    "\n",
    "Recall (чувствителност) - Recall е сооднос на правилно предвидени позитивни набудувања со сите набудувања во реалната класа.   \n",
    "\n",
    "Recall = TP / TP + FN   \n",
    "\n",
    "F1 Score = 2 * (Recall * Precision) / (Recall + Precision)   \n",
    "\n",
    "Accuracy e вредност која што е во ранг од [0,1] па така колку поголема точност тоа подобро, но исто така постои и проблемот на (анг. [Overfitting](https://en.wikipedia.org/wiki/Overfitting)). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**д) Какви видови на визуелизација се користени во трудот?**   \n",
    "- Табели\n",
    "- Scatter Plot \n",
    "- Confidence Band\n",
    "- Flow diagram\n",
    "- Connected Scatterplol\n",
    "- Multiple lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ѓ) Дали е хипотезата од трудот потврдена или одбиена?**          \n",
    "Во овој труд е претставена методологија со која што се откриваат лица кои се генерирани со алгоритми од компјутерска визија. Овој метод е во состојба да открие \n",
    "вештачко генерирани лица на слики со висока и средна резолуција со 100% точност. Притоа првичната дека тоа може да се направи со многу малку примероци за тренирање и \n",
    "едноставни карактеристики е потврдена. Сликите со висока и средна резолуција се класифицираат со 100% точност, а пак оние со ниска резолуција поради фрекфентниот спектар кој\n",
    "што е многу мал се идентификуваат исто така со доста голема точност од 91%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. (65 поени)** Направете Jupyter тетратката поврзана со трудот од првото прашање и\n",
    "прикачете ја на GitHub (доколку немате профил креирајте го, ќе ви треба). Линкот од\n",
    "вашиот Github repo мора да биде испратен до 23.59 часот на 5 декември (сите промени по\n",
    "овој краен рок нема да бидат прифатени). Исто така нема да прифаќаме тетратки\n",
    "хостирани на било кое друго место освен на Github.\n",
    "а) Тетратката треба да започне со краток опис на трудот (напишан во Markdown).\n",
    "Краткиот опис треба во стотина зборови да објасни зошто е овој труд значаен.\n",
    "б) Остатокот од тетратката го оставаме на вас. Не заборавајте дека колоквиумите\n",
    "ќе бидат рангирани, така што тие кои ќе имаат најквалитетна тетратка ќе добијат најмногу\n",
    "поени. За да биде кандидат за максимална оценка, тетратката треба да содржи три од\n",
    "овие 5 карактеристки:\n",
    "- Формули од избраниот труд напишани во LaTeX\n",
    "- Ќелии со код од избраниот труд кои може да се егзекутираат (полесно е ова\n",
    "да се направи доколку податоците и кодот од трудот се јавно достапни)\n",
    "- Интерактивна визуелизација (Plotly, ipywidgets или други алатки)\n",
    "- Вметнатно лого на журналот во кој е објавен трудот\n",
    "- Ембедиран мултимедијален запис поврзан со трудот (YouTube видео,\n",
    "podcast, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целта на ова прашање е да бидете креативни. Понудете ни тетратка која го надополнува\n",
    "оригиналниот PDF и го прави истражувањето да биде покорисно. Доколку трудот ги\n",
    "споделува податоците, тогаш можете да направите и сосема нова визуелизација.\n",
    "Изненадете нè!\n",
    "P.S. Вашитe одговори на колоквиумот треба да бидат прикачени на GitHub (во PDF или\n",
    "друг електронски формат) заедно со Jupyter тетратката."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
